{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_N9XP2-04VH"
      },
      "source": [
        "\n",
        "Our dataset consists of clinical data from patients who entered the hospital complaining of chest pain (\"angina\") during exercise.  The information collected includes:\n",
        "\n",
        "* `age` : Age of the patient\n",
        "\n",
        "* `sex` : Sex of the patient\n",
        "\n",
        "* `cp` : Chest Pain type\n",
        "\n",
        "    + Value 0: asymptomatic\n",
        "    + Value 1: typical angina\n",
        "    + Value 2: atypical angina\n",
        "    + Value 3: non-anginal pain\n",
        "   \n",
        "    \n",
        "* `trtbps` : resting blood pressure (in mm Hg)\n",
        "\n",
        "* `chol` : cholesterol in mg/dl fetched via BMI sensor\n",
        "\n",
        "* `restecg` : resting electrocardiographic results\n",
        "\n",
        "    + Value 0: normal\n",
        "    + Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
        "    + Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
        "\n",
        "* `thalach` : maximum heart rate achieved during exercise\n",
        "\n",
        "* `output` : the doctor's diagnosis of whether the patient is at risk for a heart attack\n",
        "    + 0 = not at risk of heart attack\n",
        "    + 1 = at risk of heart attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tZmjmGGQ1CaN"
      },
      "outputs": [],
      "source": [
        "## library imports here\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet , LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
        "from sklearn.metrics import r2_score,classification_report, f1_score\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ghXbwhv600-S"
      },
      "outputs": [],
      "source": [
        "ha = pd.read_csv(\"https://www.dropbox.com/s/aohbr6yb9ifmc8w/heart_attack.csv?dl=1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCX180v41bhe"
      },
      "source": [
        "## Q1: Natural Multiclass Models\n",
        "\n",
        "Fit a multiclass KNN, Decision Tree, and LDA for the heart disease data; this time predicting the type of chest pain (categories 0 - 3) that a patient experiences.  For the decision tree, plot the fitted tree, and interpret the first couple splits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WJsMBCZh1glq"
      },
      "outputs": [],
      "source": [
        "X1 = ha.drop(\"cp\", axis = 1) \n",
        "y1 = ha[\"cp\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X1, y1, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "ct = ColumnTransformer(\n",
        "  [\n",
        "    (\"dummify\", \n",
        "    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),\n",
        "    make_column_selector(dtype_include=object)),],\n",
        "  remainder = \"passthrough\"\n",
        ")\n",
        "\n",
        "pipeKNN = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"KNN\", KNeighborsClassifier())]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_knn = {\n",
        "    \"KNN__n_neighbors\": range(1,100)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'KNN__n_neighbors': 21}\n"
          ]
        }
      ],
      "source": [
        "grid = GridSearchCV(pipeKNN, param_grid_knn, cv=5, scoring='r2')\n",
        "grid.fit(X1, y1)\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeKNN = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"KNN\", KNeighborsClassifier(n_neighbors=21))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.94      0.69        36\n",
            "           1       0.00      0.00      0.00        17\n",
            "           2       0.47      0.38      0.42        24\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.52        82\n",
            "   macro avg       0.26      0.33      0.28        82\n",
            "weighted avg       0.38      0.52      0.43        82\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ldcal\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ldcal\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "C:\\Users\\ldcal\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "pipeKNN.fit(X1,y1)\n",
        "\n",
        "preds = pipeKNN.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Tree__ccp_alpha': 0.0005, 'Tree__max_depth': None, 'Tree__min_samples_leaf': 1, 'Tree__min_samples_split': 10, 'Tree__splitter': 'random'}\n"
          ]
        }
      ],
      "source": [
        "pipeTree = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"Tree\", DecisionTreeClassifier())]\n",
        ")\n",
        "\n",
        "param_grid_Tree = {\n",
        "    \"Tree__max_depth\": [None, 3, 5, 8, 12],\n",
        "    \"Tree__min_samples_split\": [2, 5, 10, 20],\n",
        "    \"Tree__min_samples_leaf\": [1, 2, 5, 10],\n",
        "    \"Tree__splitter\": [\"best\", \"random\"],\n",
        "    \"Tree__ccp_alpha\": [0.0, 0.0005, 0.001, 0.005]  \n",
        "}\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "tree_gs = GridSearchCV(pipeTree, param_grid_Tree, cv=cv, scoring = \"f1_macro\", n_jobs = -1)\n",
        "\n",
        "tree_gs.fit(X1, y1)\n",
        "print(tree_gs.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeTree = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"Tree\", DecisionTreeClassifier(ccp_alpha=0.005, max_depth=None, min_samples_leaf=1, min_samples_split=10,\n",
        "  splitter = \"random\"))]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.31143143507633464)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(pipeTree,X1, y1,cv = cv, scoring = \"f1_macro\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.64      0.63        36\n",
            "           1       0.00      0.00      0.00        17\n",
            "           2       0.36      0.58      0.44        24\n",
            "           3       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.45        82\n",
            "   macro avg       0.25      0.31      0.27        82\n",
            "weighted avg       0.38      0.45      0.41        82\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pipeTree.fit(X_train,y_train)\n",
        "\n",
        "Treepreds = pipeTree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, Treepreds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYqpOtbO1EAJ"
      },
      "source": [
        "## Q2:  OvR\n",
        "\n",
        "Create a new column in the `ha` dataset called `cp_is_3`, which is equal to `1` if the `cp` variable is equal to `3` and `0` otherwise.\n",
        "\n",
        "Then, fit a Logistic Regression to predict this new target, and report the **F1 Score**.\n",
        "\n",
        "Repeat for the other three `cp` categories.  Which category was the OvR approach best at distinguishing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "90PfjsjW1T2Y"
      },
      "outputs": [],
      "source": [
        "ha[\"cp_is_3\"] = np.where(ha['cp'] == 3, 1, 0)\n",
        "ha[\"cp_is_2\"] = np.where(ha['cp'] == 2, 1, 0)\n",
        "ha[\"cp_is_1\"] = np.where(ha['cp'] == 1, 1, 0)\n",
        "ha[\"cp_is_0\"] = np.where(ha['cp'] == 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeOvr = Pipeline(\n",
        "  [(\"preprocessing\", ct),\n",
        "  (\"ovr\",OneVsRestClassifier(LogisticRegression(max_iter=5000)))]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "X2 = ha.drop([\"cp\", \"cp_is_3\", \"cp_is_2\", \"cp_is_1\", \"cp_is_0\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for k in [0, 1, 2, 3]:\n",
        "    yk = ha.get(f\"cp_is_{k}\", (ha[\"cp\"] == k).astype(int)).astype(int)\n",
        "    scores = cross_val_score(\n",
        "        estimator=pipeOvr,\n",
        "        X=X2,\n",
        "        y=yk,\n",
        "        cv=cv,\n",
        "        scoring=\"f1_macro\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rows.append({\"cp\": k, \"F1_mean\": scores.mean(), \"F1_std\": scores.std()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp</th>\n",
              "      <th>F1_mean</th>\n",
              "      <th>F1_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.733369</td>\n",
              "      <td>0.035798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.479921</td>\n",
              "      <td>0.005878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.478069</td>\n",
              "      <td>0.050049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.455515</td>\n",
              "      <td>0.050772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cp   F1_mean    F1_std\n",
              "0   0  0.733369  0.035798\n",
              "3   3  0.479921  0.005878\n",
              "1   1  0.478069  0.050049\n",
              "2   2  0.455515  0.050772"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = pd.DataFrame(rows).sort_values(\"F1_mean\", ascending=False)\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXO3jbTU1ULR"
      },
      "source": [
        "## Q3: OvO\n",
        "\n",
        "Reduce your dataset to only the `0` and `1` types of chest pain.\n",
        "\n",
        "Then, fit a Logistic Regression to predict between the two groups, and report the **ROC-AUC**.  \n",
        "\n",
        "Repeat comparing category `0` to `2` and `3`.  Which pair was the OvO approach best at distinguishing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "THrjnRoV1siy"
      },
      "outputs": [],
      "source": [
        "ha_01 = ha[(ha[\"cp\"] == 0) | (ha[\"cp\"] == 1)]\n",
        "\n",
        "X3_1 = ha_01[[\"trtbps\", \"chol\", \"age\"]]\n",
        "y3_1 = ha_01[\"cp\"]\n",
        "\n",
        "\n",
        "logistic_model =Pipeline(\n",
        "    [(\"scale\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression())]\n",
        ")\n",
        "\n",
        "fit1 = logistic_model.fit(X3_1, y3_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6016623931623932)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(fit1, X3_1, y3_1,\n",
        "                                cv=5, scoring=\"roc_auc\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "ha_02 = ha[(ha[\"cp\"] == 0) | (ha[\"cp\"] == 2)]\n",
        "\n",
        "X3_2 = ha_02[[\"trtbps\", \"chol\", \"age\"]]\n",
        "y3_2 = ha_02[\"cp\"]\n",
        "\n",
        "\n",
        "logistic_model =Pipeline(\n",
        "    [(\"scale\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression())]\n",
        ")\n",
        "\n",
        "fit2 = logistic_model.fit(X3_2, y3_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.5593246606334841)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(fit2, X3_2, y3_2,\n",
        "                                cv=5, scoring=\"roc_auc\").mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "ha_03 = ha[(ha[\"cp\"] == 0) | (ha[\"cp\"] == 3)]\n",
        "\n",
        "X3_3 = ha_03[[\"trtbps\", \"chol\", \"age\"]]\n",
        "y3_3 = ha_03[\"cp\"]\n",
        "\n",
        "\n",
        "logistic_model =Pipeline(\n",
        "    [(\"scale\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression())]\n",
        ")\n",
        "\n",
        "fit3 = logistic_model.fit(X3_3, y3_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.5585384615384615)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_val_score(fit3, X3_3, y3_3,\n",
        "                                cv=5, scoring=\"roc_auc\").mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pair that ovo was best at modeling was cp 0 and 1 likely because it is these values probably have closer values so segmenting them is easier"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
